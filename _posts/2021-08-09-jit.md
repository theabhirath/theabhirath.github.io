---
title: A quick introduction to Just-in-Time (JIT) compilation
tags:
    - programming
---

With the constant growth in the computer science community, there is a demand for more performant and efficient code -- and as a result, more efficient compilers. Programming languages are constantly getting faster, and a lot of this has to do with people figuring out how to _optimise_ the process of executing a program.

In this article, I will be talking about Just-in-Time (JIT) compilation, a buzzword that's been around for quite some time now and has revolutionized the way code executes, whether in the browser with Google's V8 engine for JavaScript or outside it, with projects like LuaJIT, PyPy and Julia. I will be deliberately skimming over the technical aspects only very superficially to keep the article as simple and accessible as possible, but I hope to explain to the unintitated what JIT compilation is, how it helps speed up your code, and why it's arguably the future for all interpreted languages. Let's dive into it!

## Compiled and interpreted languages

The root of this entire discussion is based on the _execution_ of a program, so we're gonna focus on that for a bit. What does it mean for a language to be **compiled**?

In the interest of being technically correct, I will point out here that being compiled or interpreted is not a property of the language at all -- it is the property of a specific implementation of a language, since one language can have multiple implementations (different ways to compile/interpret and execute code). But when we refer to languages as compiled or interpreted, we usually use it to mean the default or the most popular implementation of that language -- like CPython for Python.
{: .notice--info}

A _compiler_ is a program that translates your code from one language to another -- if not mentioned otherwise, the target is typically machine code. Compiled languages are thus languages where your code is first converted to machine code, and then executed. Examples of compiled languages can be C, C++, Rust and Go. In all these languages, when you execute a program, you can clearly see the production of a file in machine code, which in its raw form can be understood by and executed by the machine.

Interpreted languages are those where your program is never converted to machine code -- instead,an intermediate program (the _interpreter_, if you will) directly executes your program. Examples of this include Lisp, Python, Ruby and PHP.

There are a lot of arguments over the classification of various languages as intepreted or compiled -- as you'll see below, the lines are not quite as clear as I've shown them to be above. In most cases, _very_ specific implementation details are what decide if a language is interpreted, compiled or something in-between both. I'll be sticking to commonly used classifications for the languages, but this is just something to bear in mind while reading other sources of information.

### Bytecode

Real-life is a little more tricky than the textbook definitions I gave you above. Truly interpreted languages are almost never used anymore, due to problems with language engineering, optimisations to make your programs execute faster and difficulties with debugging.

Languages like Python and Ruby are first _compiled_ to something called a **bytecode**. This is an intermediate "language" that's designed for the purpose of making checks and failsafes easier, and to also allow language engineers to design optimisations built into the bytecode for speed during execution. In the case of Python, you may have even seen the bytecode files if you used older versions of Python -- they have an extension of _.pyc_. The bytecode is then interpreted by a **virtual machine** (you'll also often seen these referred to as **bytecode interpreters**), which is just a fancy way of referring to a program for which the bytecode acts like the machine code (the term virtual is used because there's no such actual machine).

Syntax checks are typically run when converting the original code to bytecode. While theoretically they _can_ be run directly before the interpreter is started up, there are places where this can lead to irritating program outputs, especially such as in the following scenario:

```plaintext
sleep(10000);
bAd sYnTaX;
```

And you definitely don't want to be waiting for the best part of 3 hours only to be told that your syntax is buggy.

### Advantages and drawbacks

Compiled languages are fast -- very, _very_ fast since machine code can be run directly at the lowest level and thus benefits from the raw power of the CPU. They are also usually better designed, since everything has to be specified explicitly; have better syntax checking that ensures more errors are detected before runtime, and encourage discipline in code writing. But compiled languages _have_ to be **statically typed** i.e. the types of all variables have to be explicitly specified and in effect, _guarantee_ to the compiler that the type of the variable is what they are feeding into it. This allows the compiler to make huge optimisations with code execution at the machine level.

In contrast, interpreted languages are slower, since they're run on an intermediate program and not directly on the CPU. But interpreted languages can be **dynamically typed**, allowing for greater flexibility while writing programs, greater ease of reading and understanding, easier debugging, more interactivity (such as REPLs [^1] in the case of Python, Clojure or Julia), better implementations of prototype-based programming [^2], and innovative implementations of polymorphism that allow for powerful functions, such as **abstractions** in Clojure or **multiple dispatch** in Julia (if you aren't familiar with these examples, you can look them up, but it isn't really necessary to follow along with the rest of the article).

## What is a JIT?

The languages we call compiled languages such as C, Go or Rust use **ahead-of-time (AOT)** compilation -- the entire program is converted to machine code before it is executed. A Just-in-Time compiler compiles the program at runtime to machine code. This combines two benefit into one -- it allows for the flexibility of a dynamic-typing like environment to still avail of the enormous speed-up that executing code on the machine gives the program.

The implementation details of JITs vary from language to language, but I'll go over some of the popular ones in detail and demonstrate benchmarks wherever possible to show just how powerful JIT compilation can be.

### The most in-time JIT compiler -- Julia

The official Julia implementation uses a Just-in-Time compiler that behaves exactly how the name would lead you to believe it does. Let's consider an example to understand how this works. Say we have a function `divide(x, y)`:

```julia
function divide(x, y)
    return x / y
end
```

The way Julia deals with this is by using **multiple dispatch**, a type of polymorphism that depends on the types of _all_ inputs to a function to decide on what **method** is going to be used. To understand this quickly and concisely, let me explain with some examples.

The first time the function `divide` is called with integer arguments -- say `divide(10, 2)`, the compiler compiles a method for integers and executes it. Now, for any future points in the program, when the divide function is called with integer arguments, the compiled method is executed directly, resulting in much faster execution times.

Now suppose the divide function is called with a different set of arguments -- like `divide(5.3, 2)`. The compiler now compiles a new method, designed to work with a float and an integer, and executes it. Again, this has the same benefits -- any future calls to the same function will experience considerable speedups.

And I promised I would show why the hype was real, so here you go. There's a lot of online benchmarks with much more detail, but I chose a _very_ simple use case just for demonstration purposes. Here's a Python program to calculate the 10th fibonacci number:

```python-repl
>>> import timeit
>>> def fibonacci(i):
...     if i == 1 or i == 2:
...         return 1
...     else:
...         return fibonacci(i - 1) + fibonacci(i - 2)
...
>>> print(timeit.timeit("fibonacci(10)", globals = locals(), number = 10000) / 10000)
7.843204199999997e-06
```

So that's around 7843 ns on average. Let's look at Julia now:

```julia-repl
julia> using BenchmarkTools

julia> function fibonacci(i)
           if (i == 1 || i == 2)
               return 1
           else
               return fibonacci(i - 1) + fibonacci(i - 2)
           end
       end
fibonacci (generic function with 1 method)

julia> @btime fibonacci(10);
  145.318 ns (0 allocations: 0 bytes)
```

Obviously, experienced programmers will argue that using libraries for Python can speed up more common use cases -- for example, NumPy is competitive with Julia's inbuilt arrays and in some places may even exceed performance.  But NumPy isn't written completely in Python -- it derives its performance from C and C++, not to mention it requires specific vectorised syntax for performance. Julia can be competitive with these benchmarks with code written completely in Julia, and without having to write specifically vectorised notation.
{: .notice--primary}

### First-call time

This type of JIT compilation can also be called a lazy AOT compiler, and it helps Julia benchmark very well with fast execution times -- definitely better than languages like Python and even comparable with C. But there's a drawback that's less obvious.

Compiling code with optimisations can be a slow process for large sections of code. And for code that's going to be executed just once during the program, this can actually prove to be slower than simply interpreting the code. This is most obvious when people want to write programs that are less computationally heavy -- waiting for relatively long amounts of time for programs that aren't very involved can be annoying. While the Julia community has worked hard to introduce compiler optimisations that allow for faster first-call times, it still remains one of the major drawbacks that might cause people to prefer purely interpreted languages like Python.

But wait, you ask. What about [PyPy](https://www.pypy.org/), the JIT compiler for Python that claims to improve performance without a significant hit to first call times?

Well...remember when I introduced you to JITs?

## What _is_ a JIT, again?

Let me introduce you, once again, to JITs.

Most JIT compilers are not like Julia i.e. the compilation is not so "just-in-time" after all. Here is where we make our first deviation. They compile _optimal code_ at the _optimal time_ with as much optimisation as they can bring to the table.

In case you didn't notice, that's a _lot_ of optimism 😂.

How does this happen? The JIT compiler remain dormant for the most part, closely watching the program as the interpreter executes bytecode. Here's where the concept of **cold**, **warm** and **hot** code comes in. If some lines of code are only executed a few times in the program, they're termed as cold. An increase in frequency that's noticeable leads them to being called warm. And lines of code that are executed a large number of times are called hot code. These thresholds are different for different compilers and different languages -- their tuning is done _very_ finely indeed so as to maximise the kind of performance you can get.

The compiler deals with these in different ways. For cold code, the overhead of compiling once is way too much for a couple of executions, and so it's faster to interpret these. For warm code, depending on the specific implementation, it may or may not be JIT compiled. Some cases do use JIT compilation with optimisations that are low-hanging fruit. And hot code is JIT compiled with a _lot_ of optimisations.

Which brings me to our second deviation -- not all assembly code is written equal.

Assembly is a _vast_ world and has been worked on by some of the best performance engineers in computing to get it to execute fast. But compilers do not possess the same discriminating features that allow humans to write assembly code that can absolutely whizz -- well, not out of the box, at least. So how can we allow compilers to make optimisations to code that are based on more dynamic features of the program? (like say, what range of integers are being used in your loop so as to see whether using a data type with lesser bytes will also suffice.)

### The trade-off

The answer has been in front of us all along. An intepreter can already see these dynamic features when it executes the program for the first time, unlike an AOT compiler which simply converts the code to machine code blindly. So what happens when we use a JIT compiler with an interpreter? It now has vital knowledge about the program, allowing it to compile assembly code with optimisations specifically tweaked for higher performance, giving a _huge_ boost.

This has to be done very carefully though. For hot code, the initial time taken for **profiling** [^3] and compiling with optimisations is amortized over multiple function calls or loop runs, meaning that the overhead is significantly lower. For warm or cold code, however, care has to be taken to ensure that the optimisations used are such that the overhead from the compilation and profiling are always distributed in a way that the interpreter can't replicate the same performance. If it can, then it's preferred to let the interpreter do the work.

## Common use-cases of JIT compilers

Most interpreted languages that are in common use have a JIT implementation that improves execution times given some other trade-offs. Historically, the **Java Virtual Machine** was among the first to use a JIT compiler in some implementations, with optimisations that offered some performance benefits.

**Lua** is a dynamic programming language that serves as a lightweight language used in many places like game development or deep learning (the original Torch library for deep learning is written in Lua). And while Lua is already faster than other interpreted languages like Python, **LuaJIT** is a project that has made it approach C-like performance. While there are definitely some drawbacks (LuaJIT and Lua are developed independently, and compatibility is a bit finnicky), it is today widely considered one of the fastest dynamic language implementations.

Most Python developers are familiar with projects like **PyPy** or **Numba**, which offer JIT support for various libraries -- not to mention libraries like **PyTorch** or **JAX**, which offer JIT support for deep learning where the execution of repeated code is quite common and so large performance upgrades can be obtained.

And finally, any article on JIT compilation would be incomplete without a mention of the V8 JavaScript engine and several others that followed in its wake, that put JavaScript firmly on the map of serious web development and allowed for modern browsers like Chrome to work at the blazing speeds that they do.

---

# Conclusion

So why do I believe JIT compilation is the future? Because it's combines the best of both worlds -- compiled and interpreted languages, allowing for the features dynamic typing brings to the table and the speed that compiled languages are known for. While there was initially difficult to develop good JIT implementations for languages, recent additions to toolkits like LLVM that are used to develop languages as well as the progress in the overall understanding of performance engineering have meant that JIT compilation is being used in an increasing number of places.

I hope this article was informative, and that you enjoyed reading it! In the next article, I return to programming paradigms to talk about some shortcomings of imperative programming, and then dive into declarative (especially functional) programming to discover what the recent hype has been all about. Until next time!

---

[^1]: REPL refers to **Read-Eval-Print-Loop**, which is a feature that many modern programming languages have which allows for executing small statements in a terminal-like environment. This helps in testing snippets of code without having to compile an entire program.

[^2]: Prototype-based programming is a style of OOP that does not explicitly use classes -- objects inherit behaviours from other objects instead, known as **prototypes**. JavaScript is one language that makes use of this paradigm.

[^3]: **Profiling** is a type of program analysis that measures certain important metrics used most commonly for program optimisation, and more specifically, performance engineering. For example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls.